<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>An Introduction to Machine Learning and Neural Networks</title>

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/black.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
<section>
	<h2>An Introduction to ML</h2>
	<h3>Tom Read Cutting</h3>
	<p><a href="https://github.com/moosichu/introduction-to-neural-networks" target="_blank">Notes and Repository</a></p>
	<aside class="notes">
		Some notes are here.
	</aside>
</section>
<section>
	<h2>What is ML?</h2>
	<p>
		ML (MetaLanguage), is a general purpose functional programming language
		with popular derivatives including F# and OCaml.
	</p>
</section>
<section>
	<h2>Woops!</h2>
	<p>
		Wrong Presentation!
	</p>
</section>
<section>
	<h2>An Introduction to Machine Learning and Neural Networks</h2>
	<img width="100" data-src="img/electric_square_logo_white_transparent.svg" alt="The logo of Electric Square Ltd.">
	<h3>Tom Read Cutting</h3>
	<aside class="notes">
		Aaaah, that's better!
	</aside>
</section>
<section>
	<h2>Workshop Goals</h2>
	<ol>
		<li>Introduce Machine Learning</li>
		<li>Explain the theory behind simple Neural Networks</li>
		<li>Complete a fun neural network challenge</li>
		<li>Introduce a wide array of resources for further learning</li>
	</ol>

	<aside class="notes">
		Stress that I’m here to learn just as much as they are, I’m not an
		expert in machine learning as I only did a bit in undergrad. Also, the
		course I did covered a lot of things that weren’t neural nets, meaning
		we didn’t actually have time to cover those in depth. (The maths scared
		me, when it is actually quite straightforward).
	</aside>
</section>
<section>
	<section>
		<h2>Pre-Requisites</h2>
		<p>
			You will need:
		</p>
		<ul>
			<li><a href="https://www.python.org/">Python 3</a></li>
			<li>A text editor</li>
		</ul>
		<p>We will also download these libraries later:</p>
		<ul>
			<li><a href="https://scikit-learn.org/stable/">scikit-learn</a></li>
			<li><a href="http://www.numpy.org/">NumPy</a></li>
			<li><a href="https://github.com/hsjeong5/MNIST-for-Numpy">MNIST-for-Numpy</a></li>
		</ul>
		<aside class="notes">
			Download Python whilst I'm talking, we will cover the other libraries
			later.

			Just leaving them here for reference...

			TODO: show an aside slide explaining how to download other libs.
		</aside>
	</section>
	<section>
		<h2>Why Python?</h2>
		<p>
		Basically, it is what everyone uses.
		</p>
		<p>
		It is an incredibly powerful interpreted language with many useful
		machine learning and visualisation libraries that can interact well
		with each other.
		</p>
		<p>
		Furthermore, python is incredibly widely used for other applications,
		allowing Python+ML to enhance those massively.
		(eg. <a href="https://sidefx.com/community/spider-man-into-the-spider-verse/">Houdini+scikit-learn</a>)

		</p>
	</section>
</section>
<section>
	<h2>What is Machine Learning?</h2>
	<p>
		Machine Learning (ML) is a form of computation where a program is
		designed to solve specific tasks using models and inference, as opposed
		to relying on explicit hard-coded instructions.
	</p>
</section>
<section>
	<section>
		<h2>What types of machine learning are there?</h2>
		<p>There are three broad categories of machine learning</p>
		<ol>
			<li>Supervised Learning</li>
			<li>Unsupervised Learning</li>
			<li>Reinforcement Learning</li>
		</ol>
	</section>
	<section>
		<h2>Supervised Learning</h2>
		<p>
			When a machine learning algorithm attempts to infer a function from <em>labeled</em> training data.
		</p>
		<h3>Examples Include</h3>
		<ul>
			<li><a href="http://yann.lecun.com/exdb/mnist/">The MNIST Database</a></li>
			<li><a href="https://www.youtube.com/watch?v=Ipi40cb_RsI">MariFlow</a></li>
			<li><a href="https://ai.googleblog.com/2016/11/zero-shot-translation-with-googles.html">Google Translate</a></li>
			<li><a href="https://playground.tensorflow.org">TensorFlow Playground</a></li>
		</ul>
		<aside class="notes">
			Don't forget to pause for questions and ask if everyone is ok! (For every slide).
		</aside>
	</section>
	<section>
		<h2>Unsupervised Learning</h2>
		<p>
			When a machine learning algorithm attempts to infer some kind underlying structure to unlabelled data.
		</p>
		<h3>Examples Include</h3>
		<ul>
			<li><a href="https://towardsdatascience.com/k-means-in-real-life-clustering-workout-sessions-119946f9e8dd">Clustering Workout Sessions</a></li>
			<li><a href="https://arxiv.org/abs/1703.10593">CycleGan</a></li>
			<li><a href="https://arxiv.org/pdf/1609.04802.pdf">Super-Resolution</a></li>
			<li><a href="https://en.wikipedia.org/wiki/Edmond_de_Belamy">Edmond de Belamy</a></li>
		</ul>
	</section>
	<section>
		<h2>Reinforcement Learning</h2>
		<p>
			When a machine learning algorithm seeks to take actions in order to maximize some kind of reward.
		</p>
		<h3>Examples Include</h3>
		<ul>
			<li><a href="https://www.youtube.com/watch?v=qv6UVOQ0F44">MarI/O</a></li>
			<li><a href="https://blog.openai.com/reinforcement-learning-with-prediction-based-rewards/">Random Network Distillation</a></li>
			<li><a href="https://ai.googleblog.com/2016/01/alphago-mastering-ancient-game-of-go.html">AlphaGo</a></li>
			<li><a href="https://github.com/Unity-Technologies/ml-agents">Unity ML-Agents Toolkit</a></li>
		</ul>
	</section>
	<section>
		<h2>Recap:</h2>
		<p>We have..</p>
		<ul>
			<li class="fragment">Supervised Learning</li>
			<li class="fragment">Unsupervised Learning</li>
			<li class="fragment">Reinforcement Learning</li>
		</ul>
		<aside class="notes">
			Fragments reveal one-by-one, use this for audience engagement.
		</aside>
	</section>
</section>
<section>
	<h2>Neural Networks: An Example</h2>
	<p>
		<a href="https://playground.tensorflow.org">playground.tensorflow.org</a>
	</p>
</section>
<section>
	<section>
		<h2>Neural Networks: A Trained Example</h2>
		<p>
			The goal of a neural network (in this case!) is to model some function $f(\mathbf{x})$.
		</p>
		<p>
			Where $\mathbf{x}$ is a multi-dimensional vector, eg. $784$ values representing the pixels of a $28 \cdot 28$ image.
		</p>
		<p>
			The output could be a number the image represents.
		</p>
	</section>
	<section>
		<h2>Neural Networks: A Trained Example</h2>
		<p>
			So in this example, we want our neural network to take an image of the number $5$ and turn it into the <em>number</em> $5$.
		</p>
		<p>
			<img src="img/5.png" width="224" style="vertical-align:middle" alt="A 28 by 28 pixel handwritten image of the number five">
			$\rightarrow$ $5$
		</p>
		<aside class="notes">
			So the problem is to take a the image we see on the left, essentially an ordered list of 784 numbers, and turn it into the number on the right.

			But we need an algorithm that does this for the huge variety of handwritten numbers we might find out in the world.
		</aside>
	</section>
	<section>
		<h2>Neural Networks: An Explanation</h2>
		<p>
			A simple network, the <a href="Multilayer perceptron">multilayer perceptron</a>:
		</p>
		<img src="img/perceptron_example.png" width="400" alt="Diagram of a simple arbitrary multilayer perceptron neural network">
		<aside class="notes">
			There are many types of neural networks out there, but we will look at a simple case: the linear perceptron.

			You've probably seen many images like this. So what is going on in order for it to calculate the number five?

			A neural network can do this, but how?
		</aside>
	</section>
	<section>
		<h2>What do we have?</h2>
		<ol>
			<li>We have some layers: $1$ input layer, $1$ output layer and $0$+ <em>hidden</em> layers.</li>
			<li>Each layer has a number of neurons.</li>
			<li>The first layer has 784, the last layer has 5.</li>
			<li>Every neuron in each layer is connected to every neuron in the layer before and after.</li>
			<li>Each connection, has some kind of <em>weight</em>.</li>
		</ol>
	</section>
	<section>
		<h2>How does the data flow through the network?</h2>
		<ol>
			<li>The input neurons just output the value of the pixel that they correspond to.</li>
			<li>
				For all other neurons, we have the following equation:
				$$
					a^L_j=\sigma(b^L_j + \sum_{k=1}^{n_{L-1}} w^L_{jk} a^{L-1}_k)
				$$
				We will explore the meaning of this with drawing now...
			</li>
		</ol>
	</section>
	<section>
		<h2>The activation function</h2>
		<p>
			$\sigma$ is the <em>activation function</em>, processing all the inputs into a neuron. We will use the <em>sigmoid function</em>:
		</p>

		<p>
			$$
				\sigma (x) = \frac{1}{1 + e^{-x}}
			$$
		</p>

	</section>
	<section>
		<h2>The activation function</h2>
		<p>The output of the sigmoid function looks like this:</p>
		<img src="img/logistics_curve.png" alt="A graph of the sigmoid logistics curve, showing how it forms an 'S' shape that tends towards 1 at inputs > 6 and to 0 at inputs < -6." width="500">
	</section>
	<section>
		<h2>Neural Networks: An Explanation</h2>
		<p>
			DRAWING TIME!!!! :D
		</p>
		<aside class="notes">
			IMPORTANT: Explain how a trained network works, with drawings. Don't discuss how training works! That comes next!
		</aside>
	</section>
</section>
<section>
	<section>
		<h2>How to train a network: A single-neuron</h2>
		<p>
		<object type="image/svg+xml" data="img/single-neuron.svg" class="single-neuron-network">
			Diagram of a neural network with only a single neuron, taking a single weighted input value and bias to produce an output.
		</object>
		</p>
	</section>
	<section data-transition="slide-in fade-out">
		<h2>Some contrived example data</h2>
		<table style="display:inline;padding-right: 100px; font-size: 25px;">
			<tr><th>$x$</th><th>$y$</th></tr>
			<tr><td>-2.0</td><td>4.4</td></tr>
			<tr><td>3.7</td><td>0.5</td></tr>
			<tr><td>4.7</td><td>-0.3</td></tr>
			<tr><td>1.0</td><td>1.4</td></tr>
			<tr><td>3.4</td><td>0.4</td></tr>
			<tr><td>1.9</td><td>1.4</td></tr>
			<tr><td>0.5</td><td>2.0</td></tr>
			<tr><td>3.7</td><td>0.5</td></tr>
			<tr><td>-3.7</td><td>5.6</td></tr>
			<tr><td>-1.4</td><td>3.5</td></tr>
		</table>
		<img class="fragment fade-up" style="display:inline;vertical-align:top" src="img/single-neuron-example-data.svg" alt="A diagram of the data from the table plotted onto a graph. the points form some kind of downwards slope.">
	</section>
	<section data-transition="fade-in slide-out">
		<h2>Some contrived example data</h2>
		<table style="display:inline;padding-right: 100px; font-size: 25px;">
			<tr><th>$x$</th><th>$y$</th></tr>
			<tr><td>-2.0</td><td>4.4</td></tr>
			<tr><td>3.7</td><td>0.5</td></tr>
			<tr><td>4.7</td><td>-0.3</td></tr>
			<tr><td>1.0</td><td>1.4</td></tr>
			<tr><td>3.4</td><td>0.4</td></tr>
			<tr><td>1.9</td><td>1.4</td></tr>
			<tr><td>0.5</td><td>2.0</td></tr>
			<tr><td>3.7</td><td>0.5</td></tr>
			<tr><td>-3.7</td><td>5.6</td></tr>
			<tr><td>-1.4</td><td>3.5</td></tr>
		</table>
		<img style="display:inline;vertical-align:top" src="img/single-neuron-example-data-with-regression-line.svg" alt="The same diagram of the graph as before, but with a regression line running through the data. The line has the equation: y = -0.68x + 2.75.">
	</section>
	<section>
		<h2>The maths of a single neuron</h2>
		<p>
			We can simplify the maths down to (1 layer, 1 neuron, no activation function $\sigma$):
			$$
				a(x)=b + w x
			$$
			This closely matches our desired output function:
			$$
				y = c + m x
			$$
		</p>
	</section>
	<section>
		<h2>Finding $b$ and $w$</h2>
		<p>
			We need to train the neural network so that it finds $b$ and $w$ to best fit the data.
		</p>
		<p>
			$$
				a(x)=b + w x
			$$
		</p>
		<p>
			We can do this with a cost function.
		</p>
		<p>
			$$
				C=\sum_{i=0}^{N-1} (a(x_i) - y_i)^2
			$$
		</p>
		<p>
			Where $(x_i, y_i)$ represents each sample from our training data.
		</p>
	</section>
	<section>
		<h2>Reducing the cost</h2>
		<p>
			Now we have a cost, we can calculate a new weight and bias which minimizes the cost:
		</p>
		<p>
			$$
				w'=w-\mu\frac{\partial C}{\partial w}
			$$
		</p>
		<p>
			$$
				b'=b-\mu\frac{\partial C}{\partial b}
			$$
		</p>
		<p>
			Here, $\mu$ is what we call the <em>learning rate</em>.
		</p>
	</section>
	<section>
		<h2>Working through the maths...</h2>
		<p>
			$$
				\frac{\partial C}{\partial w} = \sum_{i=0}^{N-1} 2 x_i ((b + wx_i) - y_i)
			$$
		</p>
		<p>
			$$
				\frac{\partial C}{\partial b} = \sum_{i=0}^{N-1} 2 ((b + wx_i) - y_i)
			$$
		</p>
	</section>
	<section id="learning-factor-affects">
		<h2>Example with $\mu=0.01$</h2>
		<p>$m$ = 0.68, $c$ = 2.75</p>
		<ol style="font-size: 0.8em;">
			<li value="1">$w$ = 1.00, $b$ = 1.00</li>
			<li class="fragment" value="2">$w$ = -1.46, $b$ = 0.95</li>
			<li class="fragment" value="3">$w$ = 0.30, $b$ = 1.50</li>
			<li class="fragment" value="4">$w$ = -1.08, $b$ = 1.52</li>
			<li class="fragment" value="5">$w$ = -0.10, $b$ = 1.86</li>
			<li class="fragment" value="8">$w$ = -0.77, $b$ = 2.16</li>
			<li class="fragment" value="18">$w$ = -0.68, $b$ = 2.66</li>
			<li class="fragment" value="26">$w$ = -0.68, $b$ = 2.73</li>
			<li class="fragment" value="36">$w$ = -0.68, $b$ = 2.75</li>
		</ol>
		<aside class="notes">
			How do we choose a good mu?
		</aside>
	</section>
	<section>
		<h2>Example with $\mu=0.001$</h2>
		<p>$m$ = 0.68, $c$ = 2.75</p>
		<ol style="font-size: 0.8em;">
			<li value="1">$w$ = 1.00, $b$ = 1.00</li>
			<li value="2">$w$ = 0.75, $b$ = 1.00</li>
			<li value="3">$w$ = 0.55, $b$ = 1.00</li>
			<li value="5">$w$ = 0.24, $b$ = 1.01</li>
			<li value="8">$w$ = -0.05, $b$ = 1.06</li>
			<li value="18">$w$ = -0.40, $b$ = 1.28</li>
			<li value="57">$w$ = -0.56, $b$ = 1.97</li>
			<li value="126">$w$ = -0.64, $b$ = 2.50</li>
			<li value="357">$w$ = -0.68, $b$ = 2.74</li>
			<li value="358">$w$ = -0.68, $b$ = 2.75</li>
		</ol>
	</section>
	<section>
		<h2>Example with $\mu=0.1$</h2>
		<p>$m$ = 0.68, $c$ = 2.75</p>
		<ol style="font-size: 0.8em;">
			<li value="1">$w$ = 1.00, $b$ = 1.00</li>
			<li value="2">$w$ = -23.61, $b$ = 0.54</li>
			<li value="3">$w$ = 373.85, $b$ = 59.07</li>
			<li value="4">$w$ = -6166, $b$ = -937.5</li>
			<li value="5">$w$ = 1.015e+05, $b$ = 1.549e+04</li>
			<li value="8">$w$ = -4.535e+08, $b$ = -6.919e+07</li>
			<li value="18">$w$ = -6.652e+20, $b$ = -1.015e+20</li>
			<li value="26">$w$ = -3.599e+30, $b$ = -5.49e+29</li>
			<li value="36">$w$ = -5.279e+42, $b$ = -8.054e+41</li>
		</ol>
	</section>
	<section>
		<h2>In conclusion</h2>
		<p>
			We have worked through the maths of a single-neuron network.
		</p>
		<ol>
			<li class="fragment">Representing it with a function $a(x)=b + w x$.</li>
			<li class="fragment">Applying a cost when applied to training data $C=\sum_{i=0}^{N-1} (a(x_i) - y_i)^2$.</li>
			<li class="fragment">Calculating cost derivative w.r.t. $w$ and $b$ $\frac{\partial C}{\partial w}$, $\frac{\partial C}{\partial b}$.</li>
			<li class="fragment">Obtaining $w'=w-\mu\frac{\partial C}{\partial w}$ and $b'=b-\mu\frac{\partial C}{\partial b}$.</li>
			<li class="fragment">Run the above multiple times to train our network.</li>
			<li class="fragment">Choose a good $\mu$!</li>
		</ol>
	</section>
	<section>
		<h2>Any Questions?</h2>
		<p class="fragment">
			What glaring flaw do you potentially see with our values for $w$ and $b$?
		</p>
		<p class="fragment">
			What about the model overall?
		</p>
		<aside class="notes">
			<p>
				Note, further paragraphs appear about flaws in finding w and b, and flaws in the model overall.
				m was actually -0.7 and c was 3!
			</p>
			<p>
				Go back to earlier slide showing graph, and ask how we know a straight line is a good fit?
			</p>
			<p>
				Answer: we don't!
				Solution: More data!
			</p>
		</aside>
	</section>
</section>
<section>
	<h2>Applying maths to a "full" network</h2>
	<p>
		Given $a^L_j=\sigma(b^L_j + \sum_{k=1}^{n_{L-1}} w^L_{jk} a^{L-1}_k)$.
	</p>
	<p>
		We can use the same cost function and similarly calculate its derivative w.r.t. all weights and biases.
	</p>
	<p>
		This makes extensive use of the chain rule to <em>backpropagate</em> the cost through the network.
	</p>
	<p>
		Links at the end the presentation show the full maths behind this.
	</p>
</section>
<section>
	<h2>Before the practical...</h2>
	<h3>Any Questions?</h3>
</section>
<section>
	<h2>Applying the Principle: the MNIST dataset</h2>
	<img src="img/MnistExamples.png" alt="Rows and Columns of different digits demonstrating the handwriting found in the MNIST database" />
</section>
<section>
	<section>
		<h2>Demonstration Time!</h2>
		<ol>
			<li>Setup the project folder and install Python dependencies</li>
			<li>Download and load the dataset</li>
			<li>Train and evaluate a neural network on the dataset</li>
		</ol>
	</section>
	<section>
		<h2>Sorting project and dependencies</h2>
		<p>
			Create folder and add a text file called "process_digits.py".
		</p>
		<p>
			Then, ensuring you have Python installed, run:
			<pre><code class="bash" data-trim>
				pip install scikit-learn
				pip install numpy
			</code></pre>
		</p>
	</section>
	<section>
		<h2>Downloading <a href="http://yann.lecun.com/exdb/mnist/">the dataset</a></h2>
		<p>
			The dataset can be found at
			<a href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a>.
		</p>
		<p>
			However, we will be using <a href="https://github.com/hsjeong5/MNIST-for-Numpy">MNIST-for-Numpy</a>
			to download and then load the data into a "process_digits.py".
		</p>
		<aside class="notes">
			Make sure to show how to edit process_digits.py and run this to make sure that it all works!
		</aside>
	</section>
	<section>
		<h2>Training and evaluating a neural network</h2>
		<aside class="notes">
			Show how we will read the scikit-learn documentation in order to train a neural network!
		</aside>
	</section>
</section>
<section>
	<h2>Your Turn!</h2>
	<p>
		By the end of the session, who can come-up with the best accuracy on
		the testing data?
	</p>
</section>
<section>
	<h2>The next step...</h2>
	<p>
		Go back to playground, cover RELU and the like.
	</p>
</section>
<section>
	<h2>Useful Resources</h2>
	<ul style="font-size: 0.8em;">
		<li><a href="https://www.youtube.com/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi">Neural Networks</a> by 3blue1Brown</li>
		<li><a href="http://neuralnetworksanddeeplearning.com/">Neural Networks and Deep Learning</a> by Michael Nielsen</li>
		<li><a href="https://www.youtube.com/watch?v=bxe2T-V8XRs">Neural Networks Demystified</a> by Welch Labs</li>
		<li><a href="https://www.coursera.org/learn/machine-learning">Machine Learning Course</a> by Andrew Ng at Stanford</li>
		<li><a href="https://scikit-learn.org/stable/user_guide.html">scikit-learn user guide</a></li>
		<li class="fragment">Each Other!</li>
	</ul>
</section>
<section>
	<h2>Special Thanks</h2>
	<ul>
		<li><a href="https://github.com/huwb/">Huw Bowles</a> and <a href="https://github.com/ajweeks">AJ Weeks</a>: For help planning the workshop and providing valuable feedback</li>
		<li><a href="https://www.electricsquare.com/">Electric Square</a>: For the support in enabling the workshop</li>
		<li><a href="https://www.3blue1brown.com/">3Blue1Brown</a>: For a really helpful video series</li>
	</ul>
</section>
<section>
	<h2>Feedback</h2>
	<p>
		<a href="https://docs.google.com/forms/d/e/1FAIpQLSe_X5IR6gDsvgTyECdMi2tosAj4tpE9aM38RtY3gVbA3OJ61w/viewform?usp=sf_link">
			Please give your feedback!
		</a>
	</p>
</section>
			</div>
		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>
			// More info about config & dependencies:
			// - https://github.com/hakimel/reveal.js#configuration
			// - https://github.com/hakimel/reveal.js#dependencies
			Reveal.initialize({
				dependencies: [
					{ src: 'plugin/markdown/marked.js' },
					{ src: 'plugin/markdown/markdown.js' },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'plugin/math/math.js', async: true }
				]
			});
		</script>
	</body>
</html>
